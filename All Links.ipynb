{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Algorithms\n",
    "\n",
    "##### [Bahdanau (2014)](https://arxiv.org/pdf/1409.0473v7.pdf)\n",
    "— A really important paper that made incredible progress in Neural Machine Translation & Summarization. Most of current work in those field are based on this work.\n",
    "\n",
    "##### [Luong et al (2014)](https://arxiv.org/pdf/1508.04025.pdf) \n",
    "— Propose a new Local Attention Mechanism and a Global that is close to Bahdanau. Widely used as well.\n",
    "\n",
    "##### [Summarization with Pointer-Generator Networks](https://arxiv.org/abs/1704.04368)\n",
    "\n",
    "##### [A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/abs/1705.04304) + [blogpost](https://einstein.ai/research/blog/your-tldr-by-an-ai-a-deep-reinforced-model-for-abstractive-summarization)\n",
    "\n",
    "* https://talbaumel.github.io/blog/attention/\n",
    "* https://distill.pub/2016/augmented-rnns/\n",
    "* https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\n",
    "* https://medium.com/syncedreview/memory-attention-sequences-8522f531dd43\n",
    "* http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/\n",
    "\n",
    "\n",
    "## Memory Networks\n",
    "\n",
    "* Paper 1: 2014 (https://arxiv.org/pdf/1410.3916.pdf)\n",
    "* Paper 2: End to End Memory Networks\n",
    "\n",
    " - https://jhui.github.io/2017/03/15/Memory-network/\n",
    " - https://arxiv.org/abs/1503.08895\n",
    "\n",
    "## Hasing Tricks:\n",
    "* https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f\n",
    "* https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087\n",
    "* Fully understand the hashing trick  [Link](https://arxiv.org/abs/1805.08539)\n",
    "\n",
    "\n",
    "\n",
    "## Perplexity:\n",
    "[Link](https://medium.com/@aerinykim/perplexity-intuition-and-derivation-105dd481c8f3)\n",
    "\n",
    "\n",
    "## CNN\n",
    "\n",
    "\n",
    "## LSTM\n",
    "\n",
    "* Seq 2 Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
